{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b7ff956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException,ElementNotVisibleException,ElementClickInterceptedException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time \n",
    "\n",
    "import re\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c4126",
   "metadata": {},
   "source": [
    "# Question - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f696e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1.\n",
      "Name: \"Baby Shark Dance\"[4]\n",
      "Artist: Pinkfong Baby Shark - Kids' Songs & Stories\n",
      "Upload Date: June 17, 2016\n",
      "Views: 12.85\n",
      "----------------------------------\n",
      "Rank: 2.\n",
      "Name: \"Despacito\"[7]\n",
      "Artist: Luis Fonsi\n",
      "Upload Date: January 12, 2017\n",
      "Views: 8.16\n",
      "----------------------------------\n",
      "Rank: 3.\n",
      "Name: \"Johny Johny Yes Papa\"[14]\n",
      "Artist: LooLoo Kids\n",
      "Upload Date: October 8, 2016\n",
      "Views: 6.70\n",
      "----------------------------------\n",
      "Rank: 4.\n",
      "Name: \"Bath Song\"[15]\n",
      "Artist: Cocomelon – Nursery Rhymes\n",
      "Upload Date: May 2, 2018\n",
      "Views: 6.20\n",
      "----------------------------------\n",
      "Rank: 5.\n",
      "Name: \"Shape of You\"[16]\n",
      "Artist: Ed Sheeran\n",
      "Upload Date: January 30, 2017\n",
      "Views: 6.00\n",
      "----------------------------------\n",
      "Rank: 6.\n",
      "Name: \"See You Again\"[19]\n",
      "Artist: Wiz Khalifa\n",
      "Upload Date: April 6, 2015\n",
      "Views: 5.89\n",
      "----------------------------------\n",
      "Rank: 7.\n",
      "Name: \"Phonics Song with Two Words\"[24]\n",
      "Artist: ChuChu TV\n",
      "Upload Date: March 6, 2014\n",
      "Views: 5.30\n",
      "----------------------------------\n",
      "Rank: 8.\n",
      "Name: \"Wheels on the Bus\"[25]\n",
      "Artist: Cocomelon – Nursery Rhymes\n",
      "Upload Date: May 24, 2018\n",
      "Views: 5.24\n",
      "----------------------------------\n",
      "Rank: 9.\n",
      "Name: \"Uptown Funk\"[26]\n",
      "Artist: Mark Ronson\n",
      "Upload Date: November 19, 2014\n",
      "Views: 4.92\n",
      "----------------------------------\n",
      "Rank: 10.\n",
      "Name: \"Learning Colors – Colorful Eggs on a Farm\"[27]\n",
      "Artist: Miroshka TV\n",
      "Upload Date: February 27, 2018\n",
      "Views: 4.89\n",
      "----------------------------------\n",
      "Rank: 11.\n",
      "Name: \"Gangnam Style\"[28]\n",
      "Artist: Psy\n",
      "Upload Date: July 15, 2012\n",
      "Views: 4.80\n",
      "----------------------------------\n",
      "Rank: 12.\n",
      "Name: \"Masha and the Bear – Recipe for Disaster\"[33]\n",
      "Artist: Get Movies\n",
      "Upload Date: January 31, 2012\n",
      "Views: 4.55\n",
      "----------------------------------\n",
      "Rank: 13.\n",
      "Name: \"Dame Tu Cosita\"[34]\n",
      "Artist: El Chombo\n",
      "Upload Date: April 5, 2018\n",
      "Views: 4.35\n",
      "----------------------------------\n",
      "Rank: 14.\n",
      "Name: \"Axel F\"[35]\n",
      "Artist: Crazy Frog\n",
      "Upload Date: June 16, 2009\n",
      "Views: 3.91\n",
      "----------------------------------\n",
      "Rank: 15.\n",
      "Name: \"Sugar\"[36]\n",
      "Artist: Maroon 5\n",
      "Upload Date: January 14, 2015\n",
      "Views: 3.87\n",
      "----------------------------------\n",
      "Rank: 16.\n",
      "Name: \"Roar\"[37]\n",
      "Artist: Katy Perry\n",
      "Upload Date: September 5, 2013\n",
      "Views: 3.80\n",
      "----------------------------------\n",
      "Rank: 17.\n",
      "Name: \"Counting Stars\"[38]\n",
      "Artist: OneRepublic\n",
      "Upload Date: May 31, 2013\n",
      "Views: 3.79\n",
      "----------------------------------\n",
      "Rank: 18.\n",
      "Name: \"Sorry\"[39]\n",
      "Artist: Justin Bieber\n",
      "Upload Date: October 22, 2015\n",
      "Views: 3.66\n",
      "----------------------------------\n",
      "Rank: 19.\n",
      "Name: \"Baa Baa Black Sheep\"[40]\n",
      "Artist: Cocomelon – Nursery Rhymes\n",
      "Upload Date: June 25, 2018\n",
      "Views: 3.64\n",
      "----------------------------------\n",
      "Rank: 20.\n",
      "Name: \"Thinking Out Loud\"[41]\n",
      "Artist: Ed Sheeran\n",
      "Upload Date: October 7, 2014\n",
      "Views: 3.60\n",
      "----------------------------------\n",
      "Rank: 21.\n",
      "Name: \"Waka Waka (This Time for Africa)\"[42]\n",
      "Artist: Shakira\n",
      "Upload Date: June 4, 2010\n",
      "Views: 3.59\n",
      "----------------------------------\n",
      "Rank: 22.\n",
      "Name: \"Dark Horse\"[43]\n",
      "Artist: Katy Perry\n",
      "Upload Date: February 20, 2014\n",
      "Views: 3.52\n",
      "----------------------------------\n",
      "Rank: 23.\n",
      "Name: \"Lakdi Ki Kathi\"[44]\n",
      "Artist: Jingle Toons\n",
      "Upload Date: June 14, 2018\n",
      "Views: 3.48\n",
      "----------------------------------\n",
      "Rank: 24.\n",
      "Name: \"Faded\"[45]\n",
      "Artist: Alan Walker\n",
      "Upload Date: December 3, 2015\n",
      "Views: 3.45\n",
      "----------------------------------\n",
      "Rank: 25.\n",
      "Name: \"Perfect\"[46]\n",
      "Artist: Ed Sheeran\n",
      "Upload Date: November 9, 2017\n",
      "Views: 3.45\n",
      "----------------------------------\n",
      "Rank: 26.\n",
      "Name: \"Let Her Go\"[47]\n",
      "Artist: Passenger\n",
      "Upload Date: July 25, 2012\n",
      "Views: 3.44\n",
      "----------------------------------\n",
      "Rank: 27.\n",
      "Name: \"Girls Like You\"[48]\n",
      "Artist: Maroon 5\n",
      "Upload Date: May 31, 2018\n",
      "Views: 3.42\n",
      "----------------------------------\n",
      "Rank: 28.\n",
      "Name: \"Humpty the train on a fruits ride\"[49]\n",
      "Artist: Kiddiestv Hindi – Nursery Rhymes & Kids Songs\n",
      "Upload Date: January 26, 2018\n",
      "Views: 3.41\n",
      "----------------------------------\n",
      "Rank: 29.\n",
      "Name: \"Lean On\"[50]\n",
      "Artist: Major Lazer\n",
      "Upload Date: March 22, 2015\n",
      "Views: 3.38\n",
      "----------------------------------\n",
      "Rank: 30.\n",
      "Name: \"Bailando\"[51]\n",
      "Artist: Enrique Iglesias\n",
      "Upload Date: April 11, 2014\n",
      "Views: 3.38\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22228\\3023587909.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Extract the required details from each cell in the row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mcells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"td\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0martist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "\n",
    "# Send a GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the most viewed videos\n",
    "table = soup.find(\"table\", class_=\"wikitable sortable\")\n",
    "\n",
    "# Iterate over each row in the table\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    # Extract the required details from each cell in the row\n",
    "    cells = row.find_all(\"td\")\n",
    "    rank = cells[0].text.strip()\n",
    "    name = cells[1].text.strip()\n",
    "    artist = cells[2].text.strip()\n",
    "    upload_date = cells[4].text.strip()\n",
    "    views = cells[3].text.strip()\n",
    "\n",
    "    # Print the details\n",
    "    print(\"Rank:\", rank)\n",
    "    print(\"Name:\", name)\n",
    "    print(\"Artist:\", artist)\n",
    "    print(\"Upload Date:\", upload_date)\n",
    "    print(\"Views:\", views)\n",
    "    print(\"----------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972aac19",
   "metadata": {},
   "source": [
    "#  Question - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bcci.tv'\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "match_title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "m_time=[]\n",
    "\n",
    "\n",
    "\n",
    "#Click on INTERNATIONAL navigation\n",
    "driver.find_element(By.XPATH,\"//a[normalize-space()='INTERNATIONAL']\").click()\n",
    "\n",
    "\n",
    "for _ in range(1):\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'/html[1]/body[1]/div[2]/div[2]/div[1]/div[1]/div[1]/div[2]/div[3]/div[2]/div[1]/button[1]').click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"NoSuchElementException \")\n",
    "    \n",
    "title_tag=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "try:\n",
    "    for i in title_tag:\n",
    "        match_title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    match_title.append(\"-\")\n",
    "match_title\n",
    "\n",
    "\n",
    "series_tag=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "try:\n",
    "    for i in series_tag:\n",
    "        s_tag=i.text.split('-')\n",
    "        series.append(s_tag[0])\n",
    "except NoSuchElementException:\n",
    "    series.append(\"-\")\n",
    "    \n",
    "\n",
    "place_tag=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "try:\n",
    "    for i in place_tag:\n",
    "        p_tag=i.text.split('-')\n",
    "        place.append(p_tag[1])\n",
    "except NoSuchElementException:\n",
    "    place.append(\"-\")\n",
    "    \n",
    "\n",
    "\n",
    "date_tag=driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "try:\n",
    "    for i in date_tag:\n",
    "        date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    date.append(\"-\")\n",
    "    \n",
    "\n",
    "time_tag=driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "try:\n",
    "    for i in time_tag:\n",
    "        m_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    m_time.append(\"-\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aafead",
   "metadata": {},
   "source": [
    "#  Question - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.statisticstimes.com'\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "economy = driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "try:\n",
    "    economy.click()\n",
    "    driver.find_element(By.XPATH,'/html[1]/body[1]/div[2]/div[1]/div[2]/div[2]/div[1]/a[3]').click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(economy.get_attribute('href'))\n",
    "    \n",
    "time.sleep(3)\n",
    "try:\n",
    "    ads=driver.find_element(By.XPATH,'//div[@class=\"ns-dbyfr-e-19 button-common close-button\"]')\n",
    "    ads.click()\n",
    "    gdp = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\").click()\n",
    "except NoSuchElementException:\n",
    "    driver.get('https://www.statisticstimes.com/economy/india/indian-states-gdp.php')\n",
    "    \n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "rank=[]\n",
    "state=[]\n",
    "GSDP_19_20=[]\n",
    "GSDP_18_19=[]\n",
    "share_18_19=[]\n",
    "GDP_billion=[]\n",
    "\n",
    "\n",
    "state_rank=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for i in state_rank:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append(\"-\")\n",
    "    \n",
    "state_name=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for i in state_name:\n",
    "        state.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    state.append(\"-\")\n",
    "        \n",
    "GSDP_19_20_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for i in GSDP_19_20_tag:\n",
    "        GSDP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_19_20.append(\"-\")\n",
    "    \n",
    "GSDP_18_19_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for i in GSDP_18_19_tag:\n",
    "        GSDP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_18_19.append(\"-\")\n",
    "    \n",
    "share_18_19_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "try:\n",
    "    for i in share_18_19_tag:\n",
    "        share_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    share_18_19.append(\"-\")\n",
    "    \n",
    "GDP_billion_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "try:\n",
    "    for i in GDP_billion_tag:\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"-\")\n",
    "    \n",
    "    \n",
    "driver.close()\n",
    "\n",
    "df=pd.DataFrame({'Rank':rank,'State':state,'GSDP 19-20':GSDP_19_20,'GSDP 18-19':GSDP_18_19,'Share 18-19':share_18_19,'GDP billion':GDP_billion})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff7c35",
   "metadata": {},
   "source": [
    "# Question - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1be421",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url=\"https://github.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# Clicking on explore sub menu\n",
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "try:\n",
    "    explore.click()\n",
    "    time.sleep(5)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(explore.get_attribute('href'))\n",
    "\n",
    "    \n",
    "# Clicking on Trending under explore sub menu\n",
    "trending = driver.find_element(By.XPATH,'//*[@href=\"/trending\"]')\n",
    "try:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "    \n",
    "Repository_title= []\n",
    "Repository_description= []\n",
    "Contributors_count= []\n",
    "Language_used= []\n",
    "urls=[]\n",
    "\n",
    "#Scraping title of repository\n",
    "try:\n",
    "    Repository_title_tag=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/h1/a')\n",
    "    for i in Repository_title_tag:\n",
    "        Repository_title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Repository_title.append('-')\n",
    "    \n",
    "#Scraping description of Repository\n",
    "try:\n",
    "    description=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/p')\n",
    "    for i in description:\n",
    "        Repository_description.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Repository_description.append('-')\n",
    "\n",
    "for i in [Repository_title_tag,description]:\n",
    "    for j in i:\n",
    "        if i ==Repository_title_tag:\n",
    "            Repository_title.append(j.text)\n",
    "            urls.append(j.get_attribute('href'))\n",
    "        if i==description:\n",
    "            Repository_description.append(j.text)\n",
    "    \n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    div_list=driver.find_elements(By.XPATH,'//div[@class=\"BorderGrid BorderGrid--spacious\"]/div')\n",
    "    #Scraping count of contributors   \n",
    "    try:\n",
    "        Contributors_count.append(((div_list[-2].text).split())[1])\n",
    "    except:\n",
    "        Contributors_count.append('-')\n",
    "    #Scraping used language\n",
    "    try:\n",
    "        Language_used.append(((div_list[-1].text).split())[1::2])\n",
    "    except:\n",
    "        Language_used.append('-')\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "\n",
    "#creating Dataframe\n",
    "df=pd.DataFrame({\"Repository_title\":Repository_title[:25],\"Repository_description\":Repository_description[:25],\"Language_used\":Language_used[:25],\"Contributors_count\":Contributors_count[:25]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499ea9a",
   "metadata": {},
   "source": [
    "# Question - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url='https://www.billboard.com'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "nav=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div[1]/div/div/div[1]/button\")\n",
    "nav.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Hot 100 songs\n",
    "hot_100=driver.find_element(By.XPATH,'/html[1]/body[1]/div[3]/div[6]/div[1]/div[1]/div[1]/ul[1]/li[1]/ul[1]/li[2]/a[1]')\n",
    "hot_100.click()\n",
    "\n",
    "Name=[]\n",
    "Artist=[]\n",
    "rank=[]\n",
    "\n",
    "#Scraping name\n",
    "Name_tag=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\")\n",
    "for i in Name_tag:\n",
    "    Name.append(i.text)\n",
    "\n",
    "#Scraping artist\n",
    "Artist_tag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\")\n",
    "for i in Artist_tag:\n",
    "    Artist.append(i.text)\n",
    "\n",
    "#Scraping rank\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "for i in rankTag[:3]:\n",
    "    rank.append(i.text )\n",
    "    \n",
    "#Scraping name\n",
    "Rank=[]\n",
    "nameTag=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in nameTag:\n",
    "    Name.append(i.text )\n",
    "\n",
    "#Scraping artist\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in artistTag:\n",
    "    Artist.append(i.text )\n",
    "\n",
    "#Scraping rank\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "for i in RankTag:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "    \n",
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)\n",
    "        \n",
    "# slicing Data\n",
    "last_week_rank=Rank[0::3]\n",
    "last_week_rank.insert(0,rank[0])\n",
    "peak_rank=Rank[1::3]\n",
    "peak_rank.insert(0,rank[1])\n",
    "weeks_on_board=Rank[2::3]\n",
    "weeks_on_board.insert(0,rank[2])\n",
    "\n",
    "driver.close()\n",
    "# Create Dataframe\n",
    "df=pd.DataFrame({\"Name\":Name[:100],\"Artist\":Artist[:100],\"Last Week Rank\":last_week_rank[0:100],\"Peak Rank\":peak_rank[0:100],\"Weeks On Board\":weeks_on_board[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd97348",
   "metadata": {},
   "source": [
    "# Question - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a0dfffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n",
    "\n",
    "book_name=[]\n",
    "author_name=[]\n",
    "volumes_sold=[]\n",
    "publisher=[]\n",
    "genre=[]\n",
    "\n",
    "b_name=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[2]')\n",
    "try:\n",
    "    for i in b_name:\n",
    "        book_name.append(i.text)\n",
    "except:\n",
    "    book_name.append(\"-\")\n",
    "    \n",
    "a_name=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[3]')\n",
    "try:\n",
    "    for i in a_name:\n",
    "        author_name.append(i.text)\n",
    "except:\n",
    "    author_name.append(\"-\")\n",
    "    \n",
    "v_sold=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[4]')\n",
    "try:\n",
    "    for i in v_sold:\n",
    "        volumes_sold.append(i.text)\n",
    "except:\n",
    "    volumes_sold.append(\"-\")\n",
    "    \n",
    "b_publisher=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[5]')\n",
    "try:\n",
    "    for i in b_publisher:\n",
    "        publisher.append(i.text)\n",
    "except:\n",
    "    publisher.append(\"-\")\n",
    "    \n",
    "b_genre=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[6]')\n",
    "try:\n",
    "    for i in b_genre:\n",
    "        genre.append(i.text)\n",
    "except:\n",
    "    genre.append(\"-\")\n",
    "    \n",
    "driver.close()\n",
    "df=pd.DataFrame({'Book Name':book_name,'Author Name':author_name,'Volumes sold':volumes_sold,'Publisher':publisher,'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce1c4a6",
   "metadata": {},
   "source": [
    "# Question - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecb7ac80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,163,202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,243,088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,027,639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>302,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>261,401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>207,725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>258,348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,163,202  \n",
       "1    51 min     8.7  1,243,088  \n",
       "2    44 min     8.1  1,027,639  \n",
       "3    60 min     7.5    302,290  \n",
       "4    43 min     7.6    261,401  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     51,691  \n",
       "96   50 min     7.8     63,732  \n",
       "97   42 min     8.1    207,725  \n",
       "98   45 min       7     43,226  \n",
       "99  572 min     8.6    258,348  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url='https://www.imdb.com/list/ls095964455'\n",
    "driver.get(url)\n",
    "\n",
    "name=[]\n",
    "year=[]\n",
    "genre=[]\n",
    "run_time=[]\n",
    "ratings=[]\n",
    "votes=[]\n",
    "\n",
    "s_name=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "try:\n",
    "    for i in s_name:\n",
    "        name.append(i.text)\n",
    "except:\n",
    "    name.append(\"--\") \n",
    "    \n",
    "s_year=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "try:\n",
    "    for i in s_year:\n",
    "        year.append(i.text)\n",
    "except:\n",
    "    year.append(\"--\")   \n",
    "\n",
    "s_genre=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[5]')\n",
    "try:\n",
    "    for i in s_genre:\n",
    "        genre.append(i.text)\n",
    "except:\n",
    "    genre.append(\"--\")\n",
    "    \n",
    "r_time=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[3]')\n",
    "try:\n",
    "    for i in r_time:\n",
    "        run_time.append(i.text)\n",
    "except:\n",
    "    run_time.append(\"--\")   \n",
    "\n",
    "rating=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]/div/span[2]')\n",
    "try:\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "except:\n",
    "    ratings.append(\"--\")\n",
    "    \n",
    "vote=driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "try:\n",
    "    for i in vote:\n",
    "        votes.append(i.text)\n",
    "except:\n",
    "    votes.append(\"--\")\n",
    "    \n",
    "driver.close()\n",
    "df=pd.DataFrame({'Name':name,'Year Span':year,'Genre':genre,'Run Time':run_time,'Ratings':ratings,'Votes':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dbafe0",
   "metadata": {},
   "source": [
    "# Question - 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2aff2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute type Instances Attribute   Year  \n",
       "0    Categorical, Integer, Real      4177         8   1995   \n",
       "1          Categorical, Integer     48842        14   1996   \n",
       "2    Categorical, Integer, Real       798        38          \n",
       "3                   Categorical     37711       294   1998   \n",
       "4    Categorical, Integer, Real       452       279   1998   \n",
       "..                           ...       ...       ...    ...  \n",
       "617               Integer, Real     75840       525   2020   \n",
       "618               Integer, Real       400        50   2020   \n",
       "619                                  1014         7   2020   \n",
       "620                        Real     10129        16   2021   \n",
       "621                        Real      4000         2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url='https://archive.ics.uci.edu/ml/index.php'\n",
    "driver.get(url)\n",
    "\n",
    "#clicking on view all Dataset\n",
    "Dataset= driver.find_elements(By.XPATH,\"//span[@class='normal']/b/a\")[0].get_attribute('href')\n",
    "driver.get(Dataset)\n",
    "\n",
    "# Scraping dataset\n",
    "data=[]\n",
    "try:\n",
    "    data_tag=driver.find_elements(By.XPATH,\"//td//p[@class='normal']\")\n",
    "    for i in data_tag[8:4362]:\n",
    "        data.append(i.text )\n",
    "except:\n",
    "    data.append('-')\n",
    "    \n",
    "#slicing dataset\n",
    "Dataset_name=data[::7]\n",
    "Data_type=data[1::7]\n",
    "Task=data[2::7]\n",
    "Attribute_type=data[3::7]\n",
    "instances=data[4::7]\n",
    "attribute=data[5::7]\n",
    "Year=data[6::7]\n",
    "\n",
    "driver.close()\n",
    "#creating Dataframe\n",
    "df= pd.DataFrame({\"Dataset name\":Dataset_name,\"Data type\":Data_type,\"Task\":Task,\"Attribute type\":Attribute_type,\"Instances\":instances,\"Attribute\":attribute,\"Year\":Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baadf17",
   "metadata": {},
   "source": [
    "# Question - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58268826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "      <td>Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Codeachive learning</td>\n",
       "      <td>Data Science, Python, Data Analytics</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED</td>\n",
       "      <td>React.js, Data Science, Java, Front End, Busin...</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                Kalpana Dumpala   \n",
       "11                                        Mubarak   \n",
       "12                                 Kushal Rastogi   \n",
       "13                                 Priyanka Akiri   \n",
       "14                                   Kapil Devang   \n",
       "15                             Mahesh Babu Channa   \n",
       "16                             Vaishnavi Kudalkar   \n",
       "17                                Sakshi Chhikara   \n",
       "18                                    Ruchi Dhote   \n",
       "19                                  Manisha Yadav   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                     Executive Hiring   \n",
       "11                           Company HR   \n",
       "12                           Company HR   \n",
       "13                           HR Manager   \n",
       "14                           HR Manager   \n",
       "15                         HR Team Lead   \n",
       "16                         HR Executive   \n",
       "17                 Assistant Manager HR   \n",
       "18  Senior Executive Talent Acquisition   \n",
       "19                         HR Executive   \n",
       "\n",
       "                                       Company  \\\n",
       "0                         Data Science Network   \n",
       "1                Shore Infotech India Pvt. Ltd   \n",
       "2                     MARSIAN Technologies LLP   \n",
       "3        Enerlytics Software Solutions Pvt Ltd   \n",
       "4                              LibraryXProject   \n",
       "5   Apidel Technologies Division of Transpower   \n",
       "6                                         IFMR   \n",
       "7                  Techvantage Systems Pvt Ltd   \n",
       "8                   Weupskill- Live Wire India   \n",
       "9             CBL Data Science Private Limited   \n",
       "10                          Innominds Software   \n",
       "11                                    MoneyTap   \n",
       "12          QuantMagnum Technologies Pvt. Ltd.   \n",
       "13               Infinitive Software Solutions   \n",
       "14                              BISP Solutions   \n",
       "15                           SocialPrachar.com   \n",
       "16                         Codeachive learning   \n",
       "17               BIZ INFOTECNO PRIVATE LIMITED   \n",
       "18                       Bristlecone India Ltd   \n",
       "19                                    Easi Tax   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   Classic ASP Developer, Internet Marketing Prof...   \n",
       "1   .Net, Java, Data Science, Linux Administration...   \n",
       "2   Data Science, Artificial Intelligence, Machine...   \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...   \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...   \n",
       "5   Analytics, Business Intelligence, Business Ana...   \n",
       "6                                        Data Science   \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...   \n",
       "8   Technical Training, Software Development, Pres...   \n",
       "9   Software Development, It Sales, Account Manage...   \n",
       "10  Qa, Ui/ux, Java Developer, Java Architect, C++...   \n",
       "11  Business Intelligence, Data Warehousing, Data ...   \n",
       "12  Office Administration, Hr Administration, tele...   \n",
       "13  Oracle Dba, Data Science, Data Warehousing, ET...   \n",
       "14     Big Data, Hadoop, Data Analytics, Data Science   \n",
       "15  Social Media, digital media maketing, seo, smm...   \n",
       "16               Data Science, Python, Data Analytics   \n",
       "17  React.js, Data Science, Java, Front End, Busin...   \n",
       "18  Qlikview, Qlik Sense, Microsoft Azure, Power B...   \n",
       "19  Telecalling, Client Interaction, Marketing, Re...   \n",
       "\n",
       "                    Location  \n",
       "0                      Delhi  \n",
       "1   Hyderabad / Secunderabad  \n",
       "2                       Pune  \n",
       "3                  Ahmedabad  \n",
       "4              UK - (london)  \n",
       "5          Vadodara / Baroda  \n",
       "6                    Chennai  \n",
       "7                 Trivandrum  \n",
       "8                     Indore  \n",
       "9      Bengaluru / Bangalore  \n",
       "10  Hyderabad / Secunderabad  \n",
       "11     Bengaluru / Bangalore  \n",
       "12                    Mumbai  \n",
       "13                 Hyderabad  \n",
       "14                    Bhopal  \n",
       "15  Hyderabad / Secunderabad  \n",
       "16                    Mumbai  \n",
       "17                Chandigarh  \n",
       "18                      Pune  \n",
       "19               Navi Mumbai  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url='https://www.naukri.com/hr-recruiters-consultants'\n",
    "driver.get(url)\n",
    "\n",
    "designation_text='Data science'\n",
    "designation_search=driver.find_element(By.XPATH,'//input[@class=\"sugInp\"]')\n",
    "designation_search.send_keys(designation_text)\n",
    "\n",
    "search=driver.find_element(By.XPATH,'//button[@id=\"qsbFormBtn\"]')\n",
    "search.click()\n",
    "\n",
    "name=[]\n",
    "designation=[]\n",
    "company=[]\n",
    "skills=[]\n",
    "location=[]\n",
    "\n",
    "\n",
    "r_name=driver.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]')\n",
    "try:\n",
    "    for i in r_name:\n",
    "        name.append(i.text)\n",
    "except:\n",
    "    name.append(\"-\")\n",
    "    \n",
    "r_designation=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]')\n",
    "try:\n",
    "    for i in r_designation:\n",
    "        designation.append(i.text)\n",
    "except:\n",
    "    designation.append(\"-\")\n",
    "    \n",
    "r_company=driver.find_elements(By.XPATH,\"//a[@class='ellipsis']\")[1::2]\n",
    "try:\n",
    "    for i in r_company:\n",
    "        company.append(i.text)\n",
    "except:\n",
    "    company.append(\"-\")\n",
    "\n",
    "\n",
    "r_skills=driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')\n",
    "try:\n",
    "    for i in r_skills:\n",
    "        skills.append(i.text)\n",
    "except:\n",
    "    skills.append(\"-\")\n",
    "    \n",
    "r_location=driver.find_elements(By.XPATH,'//small[@class=\"ellipsis\"]')\n",
    "try:\n",
    "    for i in r_location:\n",
    "        if i.text == None:\n",
    "            location.append(\"--\")\n",
    "        else:\n",
    "            location.append(i.text)\n",
    "except:\n",
    "    location.append(\"--\") \n",
    "    \n",
    "driver.close()\n",
    "#creating Dataframe\n",
    "df=pd.DataFrame({\"Name\":name[:20],\"Designation\":designation[:20],\"Company\":company[:20],\"Skills\":skills[:20],\"Location\":location[:20]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0117553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
