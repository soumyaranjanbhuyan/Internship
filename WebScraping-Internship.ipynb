{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e31f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1#Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a341e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary modules\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0138c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Header Type\n",
      "0                      Main Page   h1\n",
      "1           Welcome to Wikipedia   h1\n",
      "2  From today's featured article   h2\n",
      "3               Did you know ...   h2\n",
      "4                    In the news   h2\n",
      "5                    On this day   h2\n",
      "6       Today's featured picture   h2\n",
      "7       Other areas of Wikipedia   h2\n",
      "8    Wikipedia's sister projects   h2\n",
      "9            Wikipedia languages   h2\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the header tags\n",
    "headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "# Create a data frame using pandas\n",
    "df = pd.DataFrame({'Header': [header.text for header in headers],\n",
    "                   'Type': [header.name for header in headers]})\n",
    "\n",
    "# Print the data frame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3871a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to display IMDB’s Top rated 50 movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "82d25b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url = 'https://www.imdb.com/chart/top/'\n",
    "page = requests.get(url)\n",
    "page\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "s_movies = soup.find_all('td', class_=\"titleColumn\")\n",
    "\n",
    "movies = []\n",
    "for movie in s_movies:\n",
    "    movie = movie.get_text().replace('\\n', '')\n",
    "    movie = movie.strip('')\n",
    "    movies.append(movie)\n",
    "    \n",
    "s_rating = soup.find_all('td' ,class_=\"ratingColumn imdbRating\")\n",
    "ratings = []\n",
    "for rating in s_rating:\n",
    "    \n",
    "    rating = rating.get_text().replace('\\n', '')\n",
    "    rating = rating.strip('')\n",
    "    ratings.append(rating)\n",
    "s_year = soup.find_all('span' ,class_=\"secondaryInfo\")\n",
    "years = []\n",
    "\n",
    "for i in s_year:\n",
    "    years.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ec931a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies</th>\n",
       "      <th>ratings</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      The Shawshank Redemption(1994)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      The Godfather(1972)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      The Dark Knight(2008)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      The Godfather Part II(1974)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      12 Angry Men(1957)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.      Schindler's List(1993)</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.      The Lord of the Rings: The Retur...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.      Pulp Fiction(1994)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.      The Lord of the Rings: The Fello...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.      Il buono, il brutto, il cattivo...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.      Forrest Gump(1994)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.      Fight Club(1999)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.      The Lord of the Rings: The Two ...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.      Inception(2010)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.      The Empire Strikes Back(1980)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.      The Matrix(1999)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.      GoodFellas(1990)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1990)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.      One Flew Over the Cuckoo's Nest...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.      Se7en(1995)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.      It's a Wonderful Life(1946)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.      Shichinin no samurai(1954)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.      The Silence of the Lambs(1991)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.      Saving Private Ryan(1998)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.      Cidade de Deus(2002)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.      Interstellar(2014)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.      La vita è bella(1997)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.      The Green Mile(1999)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.      Star Wars(1977)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.      Terminator 2: Judgment Day(1991)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.      Back to the Future(1985)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.      Sen to Chihiro no kamikakushi(2...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.      The Pianist(2002)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.      Psycho(1960)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1960)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.      Gisaengchung(2019)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.      Léon(1994)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.      The Lion King(1994)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.      Gladiator(2000)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.      American History X(1998)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.      The Departed(2006)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.      Whiplash(2014)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.      The Prestige(2006)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.      The Usual Suspects(1995)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.      Casablanca(1942)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1942)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.      Hotaru no haka(1988)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.      Seppuku(1962)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.      The Intouchables(2011)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.      Modern Times(1936)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1936)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.      Once Upon a Time in the West(1968)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.      Nuovo Cinema Paradiso(1988)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.      Rear Window(1954)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               movies ratings   years\n",
       "0              1.      The Shawshank Redemption(1994)     9.2  (1994)\n",
       "1                         2.      The Godfather(1972)     9.2  (1972)\n",
       "2                       3.      The Dark Knight(2008)     9.0  (2008)\n",
       "3                 4.      The Godfather Part II(1974)     9.0  (1974)\n",
       "4                          5.      12 Angry Men(1957)     9.0  (1957)\n",
       "5                      6.      Schindler's List(1993)     8.9  (1993)\n",
       "6         7.      The Lord of the Rings: The Retur...     8.9  (2003)\n",
       "7                          8.      Pulp Fiction(1994)     8.8  (1994)\n",
       "8         9.      The Lord of the Rings: The Fello...     8.8  (2001)\n",
       "9         10.      Il buono, il brutto, il cattivo...     8.8  (1966)\n",
       "10                        11.      Forrest Gump(1994)     8.8  (1994)\n",
       "11                          12.      Fight Club(1999)     8.7  (1999)\n",
       "12        13.      The Lord of the Rings: The Two ...     8.7  (2002)\n",
       "13                           14.      Inception(2010)     8.7  (2010)\n",
       "14             15.      The Empire Strikes Back(1980)     8.7  (1980)\n",
       "15                          16.      The Matrix(1999)     8.7  (1999)\n",
       "16                          17.      GoodFellas(1990)     8.7  (1990)\n",
       "17        18.      One Flew Over the Cuckoo's Nest...     8.6  (1975)\n",
       "18                               19.      Se7en(1995)     8.6  (1995)\n",
       "19               20.      It's a Wonderful Life(1946)     8.6  (1946)\n",
       "20                21.      Shichinin no samurai(1954)     8.6  (1954)\n",
       "21            22.      The Silence of the Lambs(1991)     8.6  (1991)\n",
       "22                 23.      Saving Private Ryan(1998)     8.6  (1998)\n",
       "23                      24.      Cidade de Deus(2002)     8.6  (2002)\n",
       "24                        25.      Interstellar(2014)     8.6  (2014)\n",
       "25                     26.      La vita è bella(1997)     8.6  (1997)\n",
       "26                      27.      The Green Mile(1999)     8.6  (1999)\n",
       "27                           28.      Star Wars(1977)     8.5  (1977)\n",
       "28          29.      Terminator 2: Judgment Day(1991)     8.5  (1991)\n",
       "29                  30.      Back to the Future(1985)     8.5  (1985)\n",
       "30        31.      Sen to Chihiro no kamikakushi(2...     8.5  (2001)\n",
       "31                         32.      The Pianist(2002)     8.5  (2002)\n",
       "32                              33.      Psycho(1960)     8.5  (1960)\n",
       "33                        34.      Gisaengchung(2019)     8.5  (2019)\n",
       "34                                35.      Léon(1994)     8.5  (1994)\n",
       "35                       36.      The Lion King(1994)     8.5  (1994)\n",
       "36                           37.      Gladiator(2000)     8.5  (2000)\n",
       "37                  38.      American History X(1998)     8.5  (1998)\n",
       "38                        39.      The Departed(2006)     8.5  (2006)\n",
       "39                            40.      Whiplash(2014)     8.5  (2014)\n",
       "40                        41.      The Prestige(2006)     8.5  (2006)\n",
       "41                  42.      The Usual Suspects(1995)     8.5  (1995)\n",
       "42                          43.      Casablanca(1942)     8.5  (1942)\n",
       "43                      44.      Hotaru no haka(1988)     8.5  (1988)\n",
       "44                             45.      Seppuku(1962)     8.5  (1962)\n",
       "45                    46.      The Intouchables(2011)     8.5  (2011)\n",
       "46                        47.      Modern Times(1936)     8.4  (1936)\n",
       "47        48.      Once Upon a Time in the West(1968)     8.4  (1968)\n",
       "48               49.      Nuovo Cinema Paradiso(1988)     8.4  (1988)\n",
       "49                         50.      Rear Window(1954)     8.4  (1954)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'movies' : movies,\n",
    "    'ratings': ratings,\n",
    "    'years' : years\n",
    "})\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "652b1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5bcbb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "response = requests.get(link)\n",
    "response\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "i_movies = soup.find_all('td', class_=\"titleColumn\")\n",
    "i_movies_name = []\n",
    "for movies in i_movies:\n",
    "    movies = movies.get_text().replace('\\n', '')\n",
    "    movies = movies.strip('')\n",
    "    i_movies_name.append(movies)\n",
    "    \n",
    "i_ratings = soup.find_all('td' ,class_=\"ratingColumn imdbRating\")\n",
    "i_movies_ratings = []\n",
    "for rating in i_ratings:\n",
    "    rating = rating.get_text().replace('\\n', '')\n",
    "    i_movies_ratings.append(rating)\n",
    "scraped_year = soup.find_all('span' ,class_=\"secondaryInfo\")\n",
    "scraped_year\n",
    "i_year = soup.find_all('span' ,class_=\"secondaryInfo\")\n",
    "i_year\n",
    "i_movies_year = []\n",
    "for year in i_year:\n",
    "    i_movies_year.append(year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e64893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies_name</th>\n",
       "      <th>movies_rating</th>\n",
       "      <th>movies_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      Ramayana: The Legend of Prince R...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>[(1993)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      Rocketry: The Nambi Effect(2022)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>[(2022)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      Nayakan(1987)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>[(1987)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      Gol Maal(1979)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>[(1979)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      777 Charlie(2022)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>[(2022)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.      Pariyerum Perumal(2018)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>[(2018)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.      Anbe Sivam(2003)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>[(2003)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.      Apur Sansar(1959)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>[(1959)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.      3 Idiots(2009)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>[(2009)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.      Manichitrathazhu(1993)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(1993)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.      Jai Bhim(2021)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2021)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.      #Home(2021)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2021)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.      Soorarai Pottru(2020)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2020)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.      Black Friday(2004)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2004)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.      Kumbalangi Nights(2019)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2019)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.      C/o Kancharapalem(2018)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2018)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.      Taare Zameen Par(2007)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2007)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.      Kireedam(1989)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(1989)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.      Dangal(2016)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2016)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.      Kaithi(2019)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2019)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.      Jersey(2019)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2019)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.      96(2018)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>[(2018)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.      Maya Bazaar(1957)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(1957)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.      Natsamrat(2016)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2016)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.      Asuran(2019)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2019)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.      Drishyam 2(2021)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2021)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.      Sita Ramam(2022)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2022)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.      Thevar Magan(1992)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(1992)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.      Visaaranai(2015)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2015)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.      Sarpatta Parambarai(2021)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2021)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.      Thalapathi(1991)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(1991)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.      Nadodikkattu(1987)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(1987)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.      Pather Panchali(1955)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(1955)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.      Drishyam(2013)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2013)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.      Thani Oruvan(2015)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2015)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.      Jaane Bhi Do Yaaro(1983)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(1983)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.      Vada Chennai(2018)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2018)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.      Aparajito(1956)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(1956)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.      Khosla Ka Ghosla!(2006)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2006)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.      Sardar Udham(2021)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2021)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.      Anniyan(2005)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>[(2005)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.      Ratsasan(2018)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[(2018)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.      Chupke Chupke(1975)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[(1975)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.      Gangs of Wasseypur(2012)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[(2012)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.      Drishyam(2015)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[(2015)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.      Mahanati(2018)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[(2018)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.      Peranbu(2018)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[(2018)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.      Bangalore Days(2014)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[(2014)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.      Premam(2015)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[(2015)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.      Satya(1998)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>[(1998)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          movies_name movies_rating  \\\n",
       "0         1.      Ramayana: The Legend of Prince R...           8.6   \n",
       "1            2.      Rocketry: The Nambi Effect(2022)           8.4   \n",
       "2                               3.      Nayakan(1987)           8.4   \n",
       "3                              4.      Gol Maal(1979)           8.4   \n",
       "4                           5.      777 Charlie(2022)           8.4   \n",
       "5                     6.      Pariyerum Perumal(2018)           8.4   \n",
       "6                            7.      Anbe Sivam(2003)           8.4   \n",
       "7                           8.      Apur Sansar(1959)           8.4   \n",
       "8                              9.      3 Idiots(2009)           8.4   \n",
       "9                     10.      Manichitrathazhu(1993)           8.3   \n",
       "10                            11.      Jai Bhim(2021)           8.3   \n",
       "11                               12.      #Home(2021)           8.3   \n",
       "12                     13.      Soorarai Pottru(2020)           8.3   \n",
       "13                        14.      Black Friday(2004)           8.3   \n",
       "14                   15.      Kumbalangi Nights(2019)           8.3   \n",
       "15                   16.      C/o Kancharapalem(2018)           8.3   \n",
       "16                    17.      Taare Zameen Par(2007)           8.3   \n",
       "17                            18.      Kireedam(1989)           8.3   \n",
       "18                              19.      Dangal(2016)           8.3   \n",
       "19                              20.      Kaithi(2019)           8.3   \n",
       "20                              21.      Jersey(2019)           8.3   \n",
       "21                                  22.      96(2018)           8.3   \n",
       "22                         23.      Maya Bazaar(1957)           8.2   \n",
       "23                           24.      Natsamrat(2016)           8.2   \n",
       "24                              25.      Asuran(2019)           8.2   \n",
       "25                          26.      Drishyam 2(2021)           8.2   \n",
       "26                          27.      Sita Ramam(2022)           8.2   \n",
       "27                        28.      Thevar Magan(1992)           8.2   \n",
       "28                          29.      Visaaranai(2015)           8.2   \n",
       "29                 30.      Sarpatta Parambarai(2021)           8.2   \n",
       "30                          31.      Thalapathi(1991)           8.2   \n",
       "31                        32.      Nadodikkattu(1987)           8.2   \n",
       "32                     33.      Pather Panchali(1955)           8.2   \n",
       "33                            34.      Drishyam(2013)           8.2   \n",
       "34                        35.      Thani Oruvan(2015)           8.2   \n",
       "35                  36.      Jaane Bhi Do Yaaro(1983)           8.2   \n",
       "36                        37.      Vada Chennai(2018)           8.2   \n",
       "37                           38.      Aparajito(1956)           8.2   \n",
       "38                   39.      Khosla Ka Ghosla!(2006)           8.2   \n",
       "39                        40.      Sardar Udham(2021)           8.2   \n",
       "40                             41.      Anniyan(2005)           8.2   \n",
       "41                            42.      Ratsasan(2018)           8.1   \n",
       "42                       43.      Chupke Chupke(1975)           8.1   \n",
       "43                  44.      Gangs of Wasseypur(2012)           8.1   \n",
       "44                            45.      Drishyam(2015)           8.1   \n",
       "45                            46.      Mahanati(2018)           8.1   \n",
       "46                             47.      Peranbu(2018)           8.1   \n",
       "47                      48.      Bangalore Days(2014)           8.1   \n",
       "48                              49.      Premam(2015)           8.1   \n",
       "49                               50.      Satya(1998)           8.1   \n",
       "\n",
       "   movies_year  \n",
       "0     [(1993)]  \n",
       "1     [(2022)]  \n",
       "2     [(1987)]  \n",
       "3     [(1979)]  \n",
       "4     [(2022)]  \n",
       "5     [(2018)]  \n",
       "6     [(2003)]  \n",
       "7     [(1959)]  \n",
       "8     [(2009)]  \n",
       "9     [(1993)]  \n",
       "10    [(2021)]  \n",
       "11    [(2021)]  \n",
       "12    [(2020)]  \n",
       "13    [(2004)]  \n",
       "14    [(2019)]  \n",
       "15    [(2018)]  \n",
       "16    [(2007)]  \n",
       "17    [(1989)]  \n",
       "18    [(2016)]  \n",
       "19    [(2019)]  \n",
       "20    [(2019)]  \n",
       "21    [(2018)]  \n",
       "22    [(1957)]  \n",
       "23    [(2016)]  \n",
       "24    [(2019)]  \n",
       "25    [(2021)]  \n",
       "26    [(2022)]  \n",
       "27    [(1992)]  \n",
       "28    [(2015)]  \n",
       "29    [(2021)]  \n",
       "30    [(1991)]  \n",
       "31    [(1987)]  \n",
       "32    [(1955)]  \n",
       "33    [(2013)]  \n",
       "34    [(2015)]  \n",
       "35    [(1983)]  \n",
       "36    [(2018)]  \n",
       "37    [(1956)]  \n",
       "38    [(2006)]  \n",
       "39    [(2021)]  \n",
       "40    [(2005)]  \n",
       "41    [(2018)]  \n",
       "42    [(1975)]  \n",
       "43    [(2012)]  \n",
       "44    [(2015)]  \n",
       "45    [(2018)]  \n",
       "46    [(2018)]  \n",
       "47    [(2014)]  \n",
       "48    [(2015)]  \n",
       "49    [(1998)]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    \"movies_name\" : i_movies_name,\n",
    "    \"movies_rating\" : i_movies_ratings,\n",
    "    \"movies_year\" : i_movies_year\n",
    "})\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9725d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write s python program to display list of respected former presidents of India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67c32929",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_link =\"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "response = requests.get(url_link)\n",
    "response\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "president_scrape = soup.find_all('div', class_=\"presidentListing\")\n",
    "farmer_president = []\n",
    "for names in president_scrape:\n",
    "    names = names.get_text().replace('\\n', '')\n",
    "    names = names.strip('')\n",
    "    names = names.split('(')[0]\n",
    "    farmer_president.append(names)\n",
    "terms = soup.find_all('span', class_=\"terms\")  \n",
    "term_of_office = []\n",
    "for names in president_scrape:\n",
    "    too = names.get_text().replace('\\n','')\n",
    "    too = too.split(':')[1]  \n",
    "    too = too.replace('https','')\n",
    "    too = too.replace('http','')\n",
    "    term_of_office.append(too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "036d35ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term of Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Name'] = farmer_president\n",
    "df['Term of Office'] = term_of_office\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a6cdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d75e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2359b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia\\nAUS</td>\n",
       "      <td>35</td>\n",
       "      <td>3,965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>New Zealand\\nNZ</td>\n",
       "      <td>31</td>\n",
       "      <td>3,504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>India\\nIND</td>\n",
       "      <td>47</td>\n",
       "      <td>5,294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>England\\nENG</td>\n",
       "      <td>36</td>\n",
       "      <td>3,988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pakistan\\nPAK</td>\n",
       "      <td>25</td>\n",
       "      <td>2,649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>South Africa\\nSA</td>\n",
       "      <td>31</td>\n",
       "      <td>3,141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh\\nBAN</td>\n",
       "      <td>38</td>\n",
       "      <td>3,625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Sri Lanka\\nSL</td>\n",
       "      <td>36</td>\n",
       "      <td>3,099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>West Indies\\nWI</td>\n",
       "      <td>43</td>\n",
       "      <td>3,105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Afghanistan\\nAFG</td>\n",
       "      <td>20</td>\n",
       "      <td>1,419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank              Team matches points rating ratings\n",
       "0    1    Australia\\nAUS      35  3,965    NaN     113\n",
       "1    2   New Zealand\\nNZ      31  3,504    NaN     113\n",
       "2    3        India\\nIND      47  5,294    NaN     113\n",
       "3    4      England\\nENG      36  3,988    NaN     111\n",
       "4    5     Pakistan\\nPAK      25  2,649    NaN     106\n",
       "5    6  South Africa\\nSA      31  3,141    NaN     101\n",
       "6    7   Bangladesh\\nBAN      38  3,625    NaN      95\n",
       "7    8     Sri Lanka\\nSL      36  3,099    NaN      86\n",
       "8    9   West Indies\\nWI      43  3,105    NaN      72\n",
       "9   10  Afghanistan\\nAFG      20  1,419    NaN      71"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "rows = table.findAll('tr')[1:]\n",
    "\n",
    "rank = []\n",
    "team = []\n",
    "matches =[]\n",
    "points = []\n",
    "rating = []\n",
    "for row in rows[:10]:\n",
    "    cells = row.findAll('td')\n",
    "    rank.append(cells[0].text.strip())\n",
    "    team.append(cells[1].text.strip())\n",
    "    matches.append(cells[2].text.strip())\n",
    "    points.append(cells[3].text.strip())\n",
    "    rating.append(cells[4].text.strip())\n",
    "    \n",
    "df = pd.DataFrame(columns=['Rank','Team','matches','points','rating'])\n",
    "\n",
    "df['Rank'] = rank\n",
    "df['Team'] = team\n",
    "df['matches'] = matches\n",
    "df['points'] = points\n",
    "df['ratings'] = rating\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ec0dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b) Top 10 ODI Batsmen along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e0c6807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsman</th>\n",
       "      <th>Team</th>\n",
       "      <th>rating</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Batsman Team rating Ratings\n",
       "0             Babar Azam  PAK    NaN     887\n",
       "1  Rassie van der Dussen   SA    NaN     777\n",
       "2            Imam-ul-Haq  PAK    NaN     740\n",
       "3           Shubman Gill  IND    NaN     738\n",
       "4           David Warner  AUS    NaN     726\n",
       "5            Virat Kohli  IND    NaN     719\n",
       "6        Quinton de Kock   SA    NaN     718\n",
       "7           Rohit Sharma  IND    NaN     707\n",
       "8            Steve Smith  AUS    NaN     702\n",
       "9           Fakhar Zaman  PAK    NaN     699"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'table rankings-table'})\n",
    "\n",
    "rows = table.findAll('tr')[1:]\n",
    "\n",
    "batsman = []\n",
    "team = []\n",
    "rating = []\n",
    "for row in rows[:10]:\n",
    "    cells = row.findAll('td')\n",
    "\n",
    "    \n",
    "    batsman.append(cells[1].text.strip())\n",
    "    team.append(cells[2].text.strip())\n",
    "    rating.append(cells[3].text.strip())\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(columns=['Batsman','Team','rating'])\n",
    "\n",
    "df['Batsman'] = batsman\n",
    "df['Team'] = team\n",
    "df['Ratings'] = rating\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ceffdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0250fe7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>rating</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team rating Ratings\n",
       "0    Josh Hazlewood  AUS    NaN     705\n",
       "1       Trent Boult   NZ    NaN     694\n",
       "2    Mohammed Siraj  IND    NaN     691\n",
       "3    Mitchell Starc  AUS    NaN     686\n",
       "4        Matt Henry   NZ    NaN     676\n",
       "5       Rashid Khan  AFG    NaN     659\n",
       "6        Adam Zampa  AUS    NaN     652\n",
       "7    Shaheen Afridi  PAK    NaN     641\n",
       "8  Mujeeb Ur Rahman  AFG    NaN     637\n",
       "9   Shakib Al Hasan  BAN    NaN     636"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'table rankings-table'})\n",
    "\n",
    "rows = table.findAll('tr')[1:]\n",
    "\n",
    "Player = []\n",
    "team = []\n",
    "rating = []\n",
    "for row in rows[:10]:\n",
    "    cells = row.findAll('td')\n",
    "\n",
    "    \n",
    "    Player.append(cells[1].text.strip())\n",
    "    team.append(cells[2].text.strip())\n",
    "    rating.append(cells[3].text.strip())\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(columns=['Player','Team','rating'])\n",
    "\n",
    "df['Player'] = Player\n",
    "df['Team'] = team\n",
    "df['Ratings'] = rating\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "045ee2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6af6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b7b1209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia\\nAUS</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>England\\nENG</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>South Africa\\nSA</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India\\nIND</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand\\nNZ</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies\\nWI</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh\\nBAN</td>\n",
       "      <td>13</td>\n",
       "      <td>983</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Thailand\\nTHA</td>\n",
       "      <td>11</td>\n",
       "      <td>821</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Pakistan\\nPAK</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Sri Lanka\\nSL</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank              Team matches points ratings\n",
       "0    1    Australia\\nAUS      21  3,603     172\n",
       "1    2      England\\nENG      28  3,342     119\n",
       "2    3  South Africa\\nSA      26  3,098     119\n",
       "3    4        India\\nIND      27  2,820     104\n",
       "4    5   New Zealand\\nNZ      25  2,553     102\n",
       "5    6   West Indies\\nWI      27  2,535      94\n",
       "6    7   Bangladesh\\nBAN      13    983      76\n",
       "7    8     Thailand\\nTHA      11    821      75\n",
       "8    9     Pakistan\\nPAK      27  1,678      62\n",
       "9   10     Sri Lanka\\nSL       8    353      44"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "rows = table.findAll('tr')[1:]\n",
    "\n",
    "rank = []\n",
    "team = []\n",
    "matches =[]\n",
    "points = []\n",
    "rating = []\n",
    "for row in rows[:10]:\n",
    "    cells = row.findAll('td')\n",
    "    rank.append(cells[0].text.strip())\n",
    "    team.append(cells[1].text.strip())\n",
    "    matches.append(cells[2].text.strip())\n",
    "    points.append(cells[3].text.strip())\n",
    "    rating.append(cells[4].text.strip())\n",
    "    \n",
    "df = pd.DataFrame(columns=['Rank','Team','matches','points','rating'])\n",
    "\n",
    "df['Rank'] = rank\n",
    "df['Team'] = team\n",
    "df['matches'] = matches\n",
    "df['points'] = points\n",
    "df['ratings'] = rating\n",
    "\n",
    "\n",
    "df\n",
    "df = df.drop('rating', axis = 1)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2548b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aeaf4128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsman</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Batsman Team Ratings\n",
       "0         Alyssa Healy  AUS     762\n",
       "1          Beth Mooney  AUS     754\n",
       "2      Laura Wolvaardt   SA     732\n",
       "3       Natalie Sciver  ENG     731\n",
       "4          Meg Lanning  AUS     717\n",
       "5     Harmanpreet Kaur  IND     716\n",
       "6      Smriti Mandhana  IND     714\n",
       "7  Chamari Athapaththu   SL     655\n",
       "8    Amy Satterthwaite   NZ     641\n",
       "9         Ellyse Perry  AUS     626"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'table rankings-table'})\n",
    "\n",
    "rows = table.findAll('tr')[1:]\n",
    "\n",
    "batsman = []\n",
    "team = []\n",
    "rating = []\n",
    "for row in rows[:10]:\n",
    "    cells = row.findAll('td')\n",
    "\n",
    "    \n",
    "    batsman.append(cells[1].text.strip())\n",
    "    team.append(cells[2].text.strip())\n",
    "    rating.append(cells[3].text.strip())\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(columns=['Batsman','Team','rating'])\n",
    "\n",
    "df['Batsman'] = batsman\n",
    "df['Team'] = team\n",
    "df['Ratings'] = rating\n",
    "\n",
    "df = df.drop('rating', axis = 1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37316814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2bea2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>rating</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rajeshwari Gayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team rating Ratings\n",
       "0    Sophie Ecclestone  ENG    NaN     751\n",
       "1        Jess Jonassen  AUS    NaN     723\n",
       "2       Shabnim Ismail   SA    NaN     722\n",
       "3         Megan Schutt  AUS    NaN     704\n",
       "4      Hayley Matthews   WI    NaN     660\n",
       "5           Kate Cross  ENG    NaN     655\n",
       "6       Ayabonga Khaka   SA    NaN     634\n",
       "7  Rajeshwari Gayakwad  IND    NaN     617\n",
       "8       Marizanne Kapp   SA    NaN     598\n",
       "9        Deepti Sharma  IND    NaN     589"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'table rankings-table'})\n",
    "\n",
    "rows = table.findAll('tr')[1:]\n",
    "\n",
    "Player = []\n",
    "team = []\n",
    "rating = []\n",
    "for row in rows[:10]:\n",
    "    cells = row.findAll('td')\n",
    "\n",
    "    \n",
    "    Player.append(cells[1].text.strip())\n",
    "    team.append(cells[2].text.strip())\n",
    "    rating.append(cells[3].text.strip())\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(columns=['Player','Team','rating'])\n",
    "\n",
    "df['Player'] = Player\n",
    "df['Team'] = team\n",
    "df['Ratings'] = rating\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e6f0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "326cce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Header Type\n",
      "0   Big banks including JPMorgan Chase, Bank of Am...   h2\n",
      "1                                         Latest News   h2\n",
      "2                                        QUOTE FINDER   h2\n",
      "3                                             Markets   h2\n",
      "4                                       Market MOVERS   h3\n",
      "5                                         Most Active   h3\n",
      "6                                      Unusual Volume   h3\n",
      "7                                  Latest Market News   h3\n",
      "8                                     Special Reports   h3\n",
      "9                                        Trending Now   h2\n",
      "10                              Pro News and Analysis   h2\n",
      "11                                            Ukraine   h2\n",
      "12                                 Sustainable Future   h2\n",
      "13                                        Coronavirus   h2\n",
      "14                                        CNBC Travel   h2\n",
      "15                                            Make It   h2\n",
      "16                                          News Tips   h4\n",
      "17                                  Advertise With Us   h4\n",
      "18                                   CNBC Newsletters   h4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "# Find all the header tags\n",
    "headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "# Create a data frame using pandas\n",
    "df = pd.DataFrame({'Header': [header.text for header in headers],\n",
    "                   'Type': [header.name for header in headers]})\n",
    "\n",
    "# Print the data frame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c091c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31014ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "headlines = []\n",
    "for i in soup.find_all('a', class_=\"LatestNews-headline\"):\n",
    "    headlines.append(i.text)\n",
    "    \n",
    "time = []\n",
    "for i in soup.find_all('time', class_=\"LatestNews-timestamp\"):\n",
    "    time.append(i.text)\n",
    "    \n",
    "links = []\n",
    "for link in soup.find_all('a', class_=\"LatestNews-headline\", href=True):\n",
    "    \n",
    "    links.append(link['href'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe61db71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>news-time</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpaceX to spend $2 billion on Starship this ye...</td>\n",
       "      <td>44 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/elon-musk-spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jack Dorsey criticizes Elon Musk’s leadership ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/jack-dorsey-cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banks including JPMorgan Chase, Bank of Americ...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/first-republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to raise a kids with a ‘secure’ attachment...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/how-to-raise-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The business case for green sports stadiums an...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/the-business-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A solid start to earnings season will be put t...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/decent-start-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TikTokers are using beef tallow to treat acne:...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/tiktokers-are-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This 28-year-old pays $62 a month to live in a...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/28-year-old-pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As part of the  ‘cocktail culture,' consumers ...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/cocktail-cultu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Why GM is killing the Chevy Bolt — America's c...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/why-gm-is-kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Just a few stocks are behind the market's resi...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/just-a-few-sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Google Cloud's Kurian on road to profit: 'We w...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/google-cloud-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Olipop nears $200 million in annual sales—and ...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/olipop-nears-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This 25-year-old makes $200/hour without a bac...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/25-year-old-no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The most overbought and oversold S&amp;P 500 stock...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/herea-re-the-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mark Cuban says paying Twitter for a blue chec...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/mark-cuban-pay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Goldman Sachs says these are its top picks com...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/goldman-sachs-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What’s next for SpaceX’s Starship after a dram...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/spacex-starshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jim Cramer: Consumer goods stocks are set to k...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/jim-cramer-con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Amazon drops on slowing cloud growth. Here's h...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/amazon-falls-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Why bitcoin keeps wavering between a store of ...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/why-bitcoin-ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>California bans the sale of new diesel trucks ...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/california-ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Markets next week have to contend with how agg...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/markets-next-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Here’s how one investor is finding opportuniti...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/one-investor-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>These stocks reporting next week have a histor...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/these-stocks-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>How A.I. could change the future of work</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/how-ai-could-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Carl Icahn calls Illumina Q1 results disappoin...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/carl-icahn-sla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>31% of new crypto buyers influenced by friends...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/many-new-bitco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Series I bond rates fall to 4.3% amid cooling ...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/series-i-bond-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>House votes to restore solar panel tariffs, Bi...</td>\n",
       "      <td>April 28, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/house-votes-to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headlines       news-time  \\\n",
       "0   SpaceX to spend $2 billion on Starship this ye...      44 Min Ago   \n",
       "1   Jack Dorsey criticizes Elon Musk’s leadership ...     5 Hours Ago   \n",
       "2   Banks including JPMorgan Chase, Bank of Americ...     9 Hours Ago   \n",
       "3   How to raise a kids with a ‘secure’ attachment...    10 Hours Ago   \n",
       "4   The business case for green sports stadiums an...    11 Hours Ago   \n",
       "5   A solid start to earnings season will be put t...    12 Hours Ago   \n",
       "6   TikTokers are using beef tallow to treat acne:...    12 Hours Ago   \n",
       "7   This 28-year-old pays $62 a month to live in a...    12 Hours Ago   \n",
       "8   As part of the  ‘cocktail culture,' consumers ...    13 Hours Ago   \n",
       "9   Why GM is killing the Chevy Bolt — America's c...    13 Hours Ago   \n",
       "10  Just a few stocks are behind the market's resi...    13 Hours Ago   \n",
       "11  Google Cloud's Kurian on road to profit: 'We w...    13 Hours Ago   \n",
       "12  Olipop nears $200 million in annual sales—and ...    13 Hours Ago   \n",
       "13  This 25-year-old makes $200/hour without a bac...    13 Hours Ago   \n",
       "14  The most overbought and oversold S&P 500 stock...    14 Hours Ago   \n",
       "15  Mark Cuban says paying Twitter for a blue chec...    14 Hours Ago   \n",
       "16  Goldman Sachs says these are its top picks com...    14 Hours Ago   \n",
       "17  What’s next for SpaceX’s Starship after a dram...    14 Hours Ago   \n",
       "18  Jim Cramer: Consumer goods stocks are set to k...  April 28, 2023   \n",
       "19  Amazon drops on slowing cloud growth. Here's h...  April 28, 2023   \n",
       "20  Why bitcoin keeps wavering between a store of ...  April 28, 2023   \n",
       "21  California bans the sale of new diesel trucks ...  April 28, 2023   \n",
       "22  Markets next week have to contend with how agg...  April 28, 2023   \n",
       "23  Here’s how one investor is finding opportuniti...  April 28, 2023   \n",
       "24  These stocks reporting next week have a histor...  April 28, 2023   \n",
       "25           How A.I. could change the future of work  April 28, 2023   \n",
       "26  Carl Icahn calls Illumina Q1 results disappoin...  April 28, 2023   \n",
       "27  31% of new crypto buyers influenced by friends...  April 28, 2023   \n",
       "28  Series I bond rates fall to 4.3% amid cooling ...  April 28, 2023   \n",
       "29  House votes to restore solar panel tariffs, Bi...  April 28, 2023   \n",
       "\n",
       "                                                links  \n",
       "0   https://www.cnbc.com/2023/04/29/elon-musk-spac...  \n",
       "1   https://www.cnbc.com/2023/04/29/jack-dorsey-cr...  \n",
       "2   https://www.cnbc.com/2023/04/29/first-republic...  \n",
       "3   https://www.cnbc.com/2023/04/29/how-to-raise-a...  \n",
       "4   https://www.cnbc.com/2023/04/29/the-business-c...  \n",
       "5   https://www.cnbc.com/2023/04/29/decent-start-t...  \n",
       "6   https://www.cnbc.com/2023/04/29/tiktokers-are-...  \n",
       "7   https://www.cnbc.com/2023/04/29/28-year-old-pa...  \n",
       "8   https://www.cnbc.com/2023/04/29/cocktail-cultu...  \n",
       "9   https://www.cnbc.com/2023/04/29/why-gm-is-kill...  \n",
       "10  https://www.cnbc.com/2023/04/29/just-a-few-sto...  \n",
       "11  https://www.cnbc.com/2023/04/29/google-cloud-b...  \n",
       "12  https://www.cnbc.com/2023/04/29/olipop-nears-2...  \n",
       "13  https://www.cnbc.com/2023/04/29/25-year-old-no...  \n",
       "14  https://www.cnbc.com/2023/04/29/herea-re-the-m...  \n",
       "15  https://www.cnbc.com/2023/04/29/mark-cuban-pay...  \n",
       "16  https://www.cnbc.com/2023/04/29/goldman-sachs-...  \n",
       "17  https://www.cnbc.com/2023/04/29/spacex-starshi...  \n",
       "18  https://www.cnbc.com/2023/04/28/jim-cramer-con...  \n",
       "19  https://www.cnbc.com/2023/04/28/amazon-falls-o...  \n",
       "20  https://www.cnbc.com/2023/04/28/why-bitcoin-ke...  \n",
       "21  https://www.cnbc.com/2023/04/28/california-ban...  \n",
       "22  https://www.cnbc.com/2023/04/28/markets-next-w...  \n",
       "23  https://www.cnbc.com/2023/04/28/one-investor-i...  \n",
       "24  https://www.cnbc.com/2023/04/28/these-stocks-r...  \n",
       "25  https://www.cnbc.com/2023/04/28/how-ai-could-c...  \n",
       "26  https://www.cnbc.com/2023/04/28/carl-icahn-sla...  \n",
       "27  https://www.cnbc.com/2023/04/28/many-new-bitco...  \n",
       "28  https://www.cnbc.com/2023/04/28/series-i-bond-...  \n",
       "29  https://www.cnbc.com/2023/04/28/house-votes-to...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \n",
    "    'headlines' : headlines,\n",
    "    'news-time' : time,\n",
    "    'links' : links\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0192ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df17b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "page = requests.get(url)\n",
    "page\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "page_title = []\n",
    "authors = []\n",
    "published_date = []\n",
    "paper_url = []\n",
    "\n",
    "for i in soup.find_all('a', class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    page_title.append(i.text)\n",
    "for i in soup.find_all('span', class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    authors.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    published_date.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('a', class_=\"sc-5smygv-0 fIXTHm\", href=True):\n",
    "    paper_url.append(i.get('href'))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aaee1c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>published_date</th>\n",
       "      <th>paper_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           page_title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              authors  published_date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            paper_url  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"page_title\": page_title,\n",
    "    \"authors\" : authors,\n",
    "    \"published_date\": published_date,\n",
    "    \"paper_url\": paper_url\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cb718b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9) Write a python program to scrape mentioned details from dineout.co.in and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fc196b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "page = requests.get(url)\n",
    "page\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "name = []\n",
    "for i in soup.find_all('a', class_=\"restnt-name ellipsis\"):\n",
    "    name.append(i.text)\n",
    "\n",
    "location = []\n",
    "for i in soup.find_all('div' ,class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "\n",
    "rating = []\n",
    "for i in soup.find_all('div' ,class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "\n",
    "img = []\n",
    "for i in soup.find_all('img' ,class_=\"no-img\"):\n",
    "    img.append(i.get('data-src'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa6aaac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>4</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>4.3</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name rating  \\\n",
       "0                   Castle Barbeque      4   \n",
       "1                   Jungle Jamboree    3.9   \n",
       "2                        Cafe Knosh    4.3   \n",
       "3                   Castle Barbeque    3.9   \n",
       "4              The Barbeque Company    3.9   \n",
       "5                       India Grill    3.9   \n",
       "6                    Delhi Barbeque    3.7   \n",
       "7  The Monarch - Bar Be Que Village    3.8   \n",
       "8                 Indian Grill Room    4.3   \n",
       "\n",
       "                                            location  \\\n",
       "0                     Connaught Place, Central Delhi   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi   \n",
       "4                 Gardens Galleria,Sector 38A, Noida   \n",
       "5               Hilton Garden Inn,Saket, South Delhi   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "\n",
       "                                                 img  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['name', 'rating', 'location', 'img']\n",
    "                 )\n",
    "df['name'] = name\n",
    "df['rating'] = rating\n",
    "df['location'] = location\n",
    "df['img'] = img\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd717282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
